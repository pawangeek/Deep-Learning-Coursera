{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In traditional neural language models, each token in the first input layer (in this case The cat is happy) is converted into a fixed-length word embedding before being passed into the recurrent unit. This is done either by initializing a word embedding matrix of size (Vocabulary size) x (Word embedding dimension), or by using a pretrained embedding such as GLoVe for each token<p>\n",
    "    \n",
    "In Elmo we first convert each token to an appropriate representation using character embeddings. This character embedding representation is then run through a convolutional layer using some number of filters, followed by a max-pool layer. Finally this representation is passed through a 2-layer highway network before being provided as the input to the LSTM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data=pd.read_csv(r\"../input/bbc-text.csv\")\n",
    "df2 = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future hands viewers home theatre systems p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss left books alone former worldcom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary farrell gamble leicester say rushe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle fa cup premiership side...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean twelve raids box office ocean twelve cri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future hands viewers home theatre systems p...\n",
       "1       business  worldcom boss left books alone former worldcom...\n",
       "2          sport  tigers wary farrell gamble leicester say rushe...\n",
       "3          sport  yeading face newcastle fa cup premiership side...\n",
       "4  entertainment  ocean twelve raids box office ocean twelve cri..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['text'] = df2['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Infrequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(df2['text']).split()).value_counts()[-10:]\n",
    "df2['text'] = df2['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3 Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "\n",
    "embed = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.4 Convert Sentence to Elmo Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "y = list(df2['category'])\n",
    "x = list(df2['text'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "\n",
    "def encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def decode(le, one_hot):\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "\n",
    "x_enc = x\n",
    "y_enc = encode(le, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.5 Divide dataset to test and train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.asarray(x_enc), np.asarray(y_enc), test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elmo uses bi-directional LSTM model to create word representations.<br>\n",
    "Rather than a dictionary of words and their corresponding vectors, ELMo analyses words within the context that they are used<br>\n",
    "ELMo is character based, therefore tokenizing words should not have any impact on performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example to understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08238704  0.07898229  0.08993168 ... -0.22516626  0.05554263\n",
      "   0.296727  ]]\n",
      "(1, 1024)\n"
     ]
    }
   ],
   "source": [
    "x = [\"Roasted ants are a popular snack in Columbia\"]\n",
    "\n",
    "# Extract ELMo features \n",
    "embeddings = embed(x, signature=\"default\", as_dict=True)[\"default\"]\n",
    "embeddings.shape\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "#run the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op) #execute init_op\n",
    "    new = sess.run(embeddings)\n",
    "    print(sess.run(embeddings))\n",
    "    print(new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a 2 dimensional tensor of shape (1, 1024)\n",
    "* The first dimension of this tensor represents the number of training samples. This is 1 in our case\n",
    "* The seond dimension is equal to the length of the ELMo vector\n",
    "\n",
    "Hence, every word in the input sentence has an ELMo vector of size 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.5 Train Keras neural model with ELMO Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ELMoEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elmo model** : This modules supports inputs both in the form of raw text strings or tokenized text strings<p>\n",
    "    \n",
    "**Default signature** : The module takes untokenized sentences as input. The input tensor is a string tensor with shape [batch_size]. The module tokenizes each string by splitting on spaces.\n",
    "\n",
    "**Token Signature** : With the tokens signature, the module takes tokenized sentences as input. The input tensor is a string tensor with shape [batch_size, max_length] and an int32 tensor with shape [batch_size] corresponding to the sentence length. The length input is necessary to exclude padding in the case of sentences with varying length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.squeeze** : Given a tensor input, this operation returns a tensor of the same type with all dimensions of size 1 removed. If you don't want to remove all size 1 dimensions, you can remove specific size 1 dimensions by specifying axis<p>\n",
    "**tf.cast** : The operation casts x (in case of Tensor) or x.values (in case of SparseTensor) to dtype (tf.string) here<p>\n",
    "**signature** : A string with the signature name to apply. If none, the default signature is used.<br>\n",
    "**as_dict** : If a signature has multiple inputs, they must be passed as a dict, with the keys defined by the signature. Likewise, if a      signature has multiple outputs, these can be retrieved as a dict by passing as_dict=True<p>\n",
    "**default(output)**: a fixed mean-pooling of all contextualized word representations with shape [batch_size, 1024]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "dense = Dense(256, activation='relu')(embedding)\n",
    "pred = Dense(5, activation='softmax')(dense)\n",
    "\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1024)])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Layer**: It is used to instantiate a Keras tensor<br>\n",
    "shape: A shape tuple (integers), not including the batch size. For instance, shape=(1,) indicates that the expected input will be batches of 1-d vectors<br>\n",
    "dtype: The data type expected by the input, as a string <p>\n",
    "**Lambda Layer** : Keras employs a naming scheme to define anonymous/custom layers. Lambda layers in Keras help you to implement layers or functionality that is not prebuilt and which do not require trainable weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 263,685\n",
      "Trainable params: 263,685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1780/1780 [==============================] - 190s 107ms/step - loss: 0.2463 - acc: 0.9191\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model.fit(x_train, y_train, epochs=1, batch_size=16)\n",
    "    model.save_weights('./elmo-model.h5')\n",
    "\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    model.load_weights('./elmo-model.h5')\n",
    "    predicts = model.predict(x_test, batch_size=16)\n",
    "\n",
    "y_test = decode(le, y_test)\n",
    "y_preds = decode(le, predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.tables_initializer()** : Returns an Op that initializes all tables of the default graph.<br>\n",
    "**tf.global_variables_initializers()** : Returns an Op that initializes global variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[97  0  4  0  0]\n",
      " [ 1 77  1  0  2]\n",
      " [ 3  0 80  0  0]\n",
      " [ 0  0  1 97  0]\n",
      " [ 5  3  0  0 74]]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.92      0.96      0.94       101\n",
      "entertainment       0.96      0.95      0.96        81\n",
      "     politics       0.93      0.96      0.95        83\n",
      "        sport       1.00      0.99      0.99        98\n",
      "         tech       0.97      0.90      0.94        82\n",
      "\n",
      "     accuracy                           0.96       445\n",
      "    macro avg       0.96      0.95      0.95       445\n",
      " weighted avg       0.96      0.96      0.96       445\n",
      "\n",
      "Accuracy of ELMO is: 0.9550561797752809\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test, y_preds))\n",
    "print(metrics.classification_report(y_test, y_preds))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy of ELMO is:\",accuracy_score(y_test,y_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
